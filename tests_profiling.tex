%%
%%
%% tests_profiling.tex for  in /doctorat/ece/partenariat/cours/outils_gnu
%%
%% Made by Philippe THIERRY
%% Login   <Philippe THIERRYreseau-libre.net>
%%
%% Started on  Wed Sep  1 18:08:07 2010 Philippe THIERRY
%% Last update lun. 13 sept. 2010 22:27:16 CEST Philippe THIERRY
%%

\chapter{Les outils de test et de profiling des applicatifs}


{\it Ce chapitre décrit les différents logiciels qui permettent de valider
le comportement de l'élément produit. Il décrit comment, dans le domaine
industriel, sont considérés les outils et mesures de validation et de
profiling.\\
Ces méthodes de durcissement du logiciel sont très importantes dans les
domaines de l'embarqué critique, du temps réel ou encore de la sécurité
car ils sont à l'origine de la qualité logicielle.}

\section{Du travail de développeur à l'ingénieur en génie logiciel}

\paragraph{}
Au delà de la production logicielle telle que vue dans les paragraphes
précédents, il  convient de mettre en  {\oe}uvre d'autres  outils afin de
s'assurer de la bonne qualité des logiciels.

\paragraph{}
Le  concept  de qualité logicielle doit   être instancié sur plusieurs
axes    au prorata des  objectifs  à  atteindre.  Parmi les différents
critères que l'on   peut retenir, on peur citer :

\begin{itemize}
\item {\bf le taux  de commentaire}\\
C'est un point important, car  au delà  du langage utilisé, le logiciel
produit doit être commenté afin d'expliquer   soit des formules,
soit des constructions logicielles particulières.   Il faut considérer
à  ce  niveau qu'un logiciel doit  pouvoir être amélioré, maintenu  et
corrigé par  des individus qui   n'ont    pas nécessairement les mêmes
niveaux d'expertise  que  le ou les auteur(s)  original(aux). Ils n'ont
pas non   plus forcément la même approche de la conception du
logiciel.\\
Une  manière simple de mesurer les  commentaires consiste à évaluer  le
rapport  entre le  nombre de lignes  de code  et le nombre  de  lignes de
commentaires.  Une valeure correcte de  30\% est acceptable,   sous réserve
que les  commentaires soient pertinents, ce qui hélas n'est pas aisé à
mesurer de manière automatique.

\item {\bf la capacité à fournir  des  tests}\\
Dans la mesure   où il  existe  un logiciel  réalisant  une  fonction
particulière,  on peut s'attendre à  disposer de logiciels de test
permettant d'en assurer de manière plus  ou moins automatique la vérification.\\
Un intérêt  majeur des tests est la  capacité à effectuer de  manière
automatique une vérification de conformité à des résultats attendus. Ils
fournissent de plus la possibilité à terme d'effectuer  des tests de non
régression. Ces tests permettent, lors de l'ajout ou de la correction de
code, de s'assurer que le logiciel continue de réussir les tests précédement
valides. Dans le cas contraire, on parle de régression.\\
Il s'agit ici de la même idée  que dans le domaine   automobile ou sur
les  chaines de production  de voitures : les robots  se calibrent seuls,
mesurent l'usure    de leurs outils et  vérifient   pour  chaque pièce la bonne
conformité sur  des états de surface par exemple.
Dans  le  monde  du logiciel, on parle alors de {\it tests unitaires}.\\
Ainsi, selon la découpe statique originale du projet  en fichiers sources,
on devrait trouver au moins un fichier de test par fichier source.  Chacun d'entre
eux doit générer un exécutable. Ce dernier a pour objectif d'appeler au moins une
fonction du logiciel à  tester, une ou plusieurs fois, afin de s'assurer que le résultat
produit par cette fonction est conforme à l'attendu. On parle alors de couverture
en {\it mode bloc}\\
Bien évidement,  de telles pratiques  sont très coûteuse   dans  la
mesure ou    pour une  seule      ligne de code opérationnelle, on  va
devoir rédiger environ trois à dix fois  plus de lignes de code de test,
dans le but de vérifier divers cas d'usage de la fonction testée.\\
Le nombre de lignes de code de test nécessaires à valider le comportement d'une ligne de code
opérationnelle n'est par fortuit. Il dépend de la criticité du logiciel.
Cela  dépend du domaine d'activité et  des enjeux du projet.
Par exemple, dans  le  cas de systèmes critiques  (nucléaire, militaire, avionique ou
satellite), il  est  demandé de faire des tests jusqu'à ce que {\it tous}
les  cas d'exécution de chaque ligne du logiciel   soient couverts.\\
Ceci  est   bien  défini dans une  norme internationale appellée DO178B
dont l'objectif est de caractériser de manière formelle  des systèmes
complexes  à logiciels prépondérants.\\
On peut donc conclure que selon le domaine dans lequel le logiciel est implémenté, l'effort de test
peut être soit peu couteux, soit beaucoup plus couteux que l'effort d'implémentation du logiciel
lui-même.
\end{itemize}

\section{Mesure du taux de counverture avec Gcov}

\paragraph{}
Il existe des outils pour mesurer le taux de couverture des exécutables de test décrits au dessus.
Dans le monde open-source, il existe Gcov, qui fait parti de la suite gcc.\\
Il s'agit d'un outil de métrologie du logiciel mode  bloc:\\
Lors de l'exécution des logiciels de test, cet outil permet, en concaténant la couverture de chacun
d'entre eux, de définir, par bloc fonctionnel, quel sous ensemble du code du logiciel cible a été
testé.\\
Gcov ne nécessite pas de construire un système de tests automatiques, mais c'est cependant
fortement conseillé, car cela accélère grandement la vérification, au vue du nombre parfois grand
de logiciels de test. De plus, cela fournit un cadre formel à l'exécution des tests.\\
Le schéma \ref{fig:gcov} montre un exemple de résultat de taux de couverture sur du code C. Il
est indiqué pour chaque ligne le nombre d'exécutions effectuées. Les lignes n'ayant pas été
exécutées sont indiquées en rouge.

\begin{figure}[ht]
\begin{center}
\includegraphics[width=6cm]{pictures/lcov}
\end{center}
\label{fig:gcov}
\caption{Taux de couverture par ligne de code avec Gcov}
\end{figure}



\paragraph{}
Sous réserve de faire quelques efforts supplémentaires afin d'intégrer cet  outillage dans
le Makefile, on se  rapproche de  plus en  plus d'outillages industriels  comparables à
ceux de l'industrie automobile par exemple.\\
Les éléments que fournit gcov permettent de savoir si l'implémentation des campagnes de test sont
compatibles des exigences d'entrée du logiciel. Ces dernières sont souvent définies sous forme d'un
taux de couverture (en pourcentage). Le schéma précédent permet ainsi de savoir quand ce taux est
atteint. En effet, faire plus de tests que demandé implique un surcoût qu'il est préférable
d'éviter afin de respecter le devis initial.

\section{Définition du profil d'exécution avec Gprof}

\paragraph{}
Au travers de l'exécution des logiciels de test il peut être  intérresant
de vérifier  le comportement temporel des fonctions testées  en terme de boucles
et d'appel de  fonctions.  C'est le rôle de  l'outil {\texttt gprof}\index{Gprof}
qui à  l'instar de {\texttt gcov} va permettre de fournir des graphes permettant
d'analyser le bon comportement de ces dernières. Il est de plus possible de mesurer le comportement
du logiciel lui même en simulant un environnement d'exécution représentatif du besoin.\\
Le schéma \ref{fig:gprof} montre un arbre d'exécution d'un logiciel complet. Il indique l'abre
d'appel des différentes fonctions, ainsi que pour chacune, le nombre d'appels et le coût relatif à
la durée d'exécution de chaque fonction. Cela permet entre autre de détecter les fonctions
anormalement longues.

\begin{figure}[ht]
\begin{center}
\begin{changemargin}{-1cm}{1cm}
\includegraphics[width=18cm]{pictures/gprof2dot}
\end{changemargin}
\end{center}
\label{fig:gprof}
\caption{Exemple de graphe d'appel résultant de l'exécution de GProf}
\end{figure}

\subsection{Mesurer la complexité d'un source: pmccabe}

\paragraph{}
comme vu précédment,    compte  tenu    que   l'effort     de test    peut être
particulièrement couteux, il est intéressant de savoir à l'avance quel
va être le coût futur de la rédaction des  tests et par la même occasion le  coût  de
maintenance  du  logiciel.   En  effet,  dans les grands  programmes
industriels où   les durées  de  vie   des systèmes   sont  importants
(nucléaire,aéronautique), est-il possible  d'élaborer un ou  plusieurs
critères  permettant de définir  le caractère {\it complexe} du  logiciel ? 
Cette question est d'autant plus cruciale  que selon la réponse, l'effort de test peut être être
plus important et l'effort  de maintenance plus élevé.

\paragraph{}
C'est à cette question que répond l'outil pmccabe, créé par George P. MacCabe, professeur
de statistique de l'université de Purdue University aux Etats Unis, dans le cadre de
sa thèse de statistiques appliquées à l'informatique.\\

\paragraph{}
Cet outil définit un indice de complexité appartenant à l'ensemble des entiers positifs non nuls.
Cet  indice  s'appelle {\it complexité cyclomatique}.  Il caractérise, pour un bloc de code donné,
la complexité associée. Cela permet ainsi de définir une valeur cyclomatique pour une fonction, et
dans le cadre d'un projet complet une valeur cyclomatique moyenne.\\
Plus la valeur cyclomatique est élevée, plus la complexité associée est grande. Des éléments
entrant en ligne de compte dans l'accroissement de la valeur cyclomatiques sont le nombre de branchements,
ou encore le nombre de sortie possible d'un bloc. En effet, plus leur nombre augmentent, plus le
nombre de chemins d'exécution augmentent, et plus le comportement du bloc devient complexe. Une
conséquence directe est le nombre de fichiers de tests nécessaire pour vérifier les différents
chemins d'exécution possible du bloc.\\
En étudiant la plupart des logiciels open-source, on tombe régulièrement sur une valeur moyenne du
nombre cyclomatique d'environ 30, avec un certain nombre de fonctions pouvant atteindre 250 ou plus.
A titre   d'information,  on considère  qu'une   personne normale peut comprendre un logiciel
dont le nombre cyclomatique est inférieur à 9.\\
Dans certains projets industriels, l'exigence de valeur cyclomatique inférieure à 9 peut être
demandée. Dans certains projets très critiques, il peut être demandé une valeur cyclomatique ne
dépassant pas 6. Le meilleur moyen de ce rendre compte de ce que cela veut dire est de tester
l'outil sur quelques fonctions, afin de comprendre à quel point il peut être complexe de respecter
cette exigence.

\section{Validation de la configuration mémoire et de l'emploi des caches}

\subsection{Valgrind}

\paragraph{}
Valgrind est un outil open-source permettant de fournir des informations sur la consommation
mémoire dynamique d'un programme. Il ne nécessite pas de recompiler le programme cible, son
fonctionnement s'appuyant sur une substitution des appels aux fonctions de gestion mémoire de la
libc par ces propres fonctions. Ceci permet, de manière transparente, de détecter des éléments
comme :
\begin{itemize}
\item La consommation mémoire lors d'une exécution donnée
\item Le nombre d'allocations et de désallocations de mémoire
\item Les buffers overflows
\item Les fuites mémoire
\end{itemize}

\subsection{Cachegrind}

\paragraph{}
Cachegrind est un programme de la famille de Valgrind, mais qui se concentre sur la gestion du
cache de données. Il prend un programme en argument et fournit, pour une exécution donnée de
celui-ci, la consommation du cache de donnée, le taux de cache-hits et de cache-miss, et d'autres
éléments d'information liés aux caches.\\
Cachegrind implémente un simulateur d'algorithmes de caches de type LRU avec un cache à deux niveaux.
C'est d'ailleurs sa faiblesse : peu d'algorithmes de caches sont implémentés. C'est cependant une
base très intéressante pour définir le profil de consommation de cache d'un programme.

\subsection{Mesurer la lourdeur d'un projet: sloccount}

\paragraph{}
Le programme {\it sloccount} est un binaire fournissant des données de métrologie sur les sources
d'un projet. Il fournit le nombre de lignes de code détectées dans un fichier ou un répertoire, par
langage. Il fournit également le coût théorique de l'implémentation du projet, en heures et en
dollars, à partir du nombre de lignes de code trouvées.

\section{Synthèse}

\paragraph{}
Il existe un grand nombre de projets fournissant des informations utiles tant au développeur qu'à
l'intégrateur. Ils sont peu employés par la communauté mais ont une réelle valeur ajoutée dans le
cadre de systèmes industriels. Tous ces outils contribuent un métier : le génie logiciel.

